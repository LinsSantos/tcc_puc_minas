{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sublime-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "injured-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.sort_values(by='dias_entrega',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df['dias_entrega'] > 40)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df[(df['customer_state'] != df['seller_state']) & (df['dias_entrega'] > 16)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-handling",
   "metadata": {},
   "source": [
    "# 4 - Análise e exploraçáo dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "missing-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leitura da base\n",
    "\n",
    "path_df_final_csv = 'd:/tcc_puc_minas/dataframe_final/df_final.csv'\n",
    "\n",
    "df = pd.read_csv(path_df_final_csv,sep='|')\n",
    "\n",
    "df['review_score'] = df['review_score'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-police",
   "metadata": {},
   "source": [
    "## 4.1. Análise univariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "grave-turkish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_num:  ['pib_mun_customer', 'pib_mun_seller', 'product_photos_qty', 'dias_entrega', 'price', 'freight_value']\n",
      "var_cat:  ['customer_city', 'customer_state', 'atividade_mun_customer', 'seller_city', 'seller_state', 'atividade_mun_seller', 'product_category_name', 'payment_type', 'review_score']\n"
     ]
    }
   ],
   "source": [
    "var_num = []\n",
    "var_cat = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtypes == 'object':\n",
    "        var_cat.append(col)\n",
    "    else:\n",
    "        var_num.append(col)\n",
    "\n",
    "print('var_num: ',var_num)\n",
    "print('var_cat: ',var_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-aggregate",
   "metadata": {},
   "source": [
    "### 4.1.1. Variáveis Quantitativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-service",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-transmission",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-missouri",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-mauritius",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-milton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-arrival",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-uganda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-namibia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-professional",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "junior-bottom",
   "metadata": {},
   "source": [
    "#### 4.1 - vizualizando a varável alvo, review_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando um dataframe que faz a contagem dos elementos de review_score\n",
    "\n",
    "review_score_count_series = df['review_score'].value_counts()\n",
    "print(review_score_count_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_score_count = pd.DataFrame(review_score_count_series)\n",
    "df_review_score_count = df_review_score_count.reset_index()\n",
    "df_review_score_count.columns = ['review_score','qtd']\n",
    "display(df_review_score_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazendo um bar plot de review_scores\n",
    "\n",
    "plt.figure(figsize=(15,7.5))\n",
    "sns.barplot(x='review_score',y='qtd',data=df_review_score_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregação pelo valor pago e frete\n",
    "df_agg_rs_price_freight = df.groupby('review_score').agg({'review_score':'count','price':'sum','freight_value':'sum'})\n",
    "df_agg_rs_price_freight.columns = ['rs_count','price_sum','freight_value_sum']\n",
    "df_agg_rs_price_freight = df_agg_rs_price_freight.reset_index()\n",
    "\n",
    "# fez-se então os dois percentuais juntos\n",
    "df_agg_rs_price_freight['rs_percent'] = (df_agg_rs_price_freight['rs_count']/df_agg_rs_price_freight['rs_count'].sum())*100\n",
    "df_agg_rs_price_freight['price_sum_percent'] = (df_agg_rs_price_freight['price_sum']/df_agg_rs_price_freight['price_sum'].sum())*100\n",
    "df_agg_rs_price_freight['freight_value_sum_percent'] = (df_agg_rs_price_freight['freight_value_sum']/df_agg_rs_price_freight['freight_value_sum'].sum())*100\n",
    "\n",
    "display(df_agg_rs_price_freight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrupamento dos elementos de review_score\n",
    "\n",
    "df['review_score'] = df['review_score'].apply(lambda x: 1 if x > 3 else 0)\n",
    "\n",
    "print(df['review_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazendo um describe de todos os campos\n",
    "\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_num = []\n",
    "var_cat = []\n",
    "\n",
    "for col in list(df.columns):\n",
    "    if df[col].dtype != 'object':\n",
    "        var_num.append(col)\n",
    "    else:\n",
    "        var_cat.append(col)\n",
    "        \n",
    "print(var_num)\n",
    "print(var_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-missile",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "var_num_plot = ['customer_city_idhm', 'seller_city_idhm', 'product_photos_qty', 'price', 'freight_value', 'dias_entrega']\n",
    "\n",
    "nrows = len(var_num_plot)*2\n",
    "ncols = 1\n",
    "index_num = 0\n",
    "\n",
    "# fig = plt.figure(figsize=(20,60))\n",
    "# fig.subplots_adjust(wspace=0.01,hspace=0.4)\n",
    "\n",
    "for col in var_num_plot:\n",
    "        \n",
    "        fig = plt.figure(figsize=(20,60))\n",
    "        \n",
    "        index_num = index_num + 1\n",
    "        if index_num == 13:\n",
    "            break\n",
    "        plt.subplot(nrows,ncols,index_num)\n",
    "        plt.title('Histograma de {}'.format(col))\n",
    "        plt.xlabel(col)\n",
    "        sns.histplot(data=df[col])\n",
    "\n",
    "        plt.grid()\n",
    "\n",
    "        index_num = index_num + 1\n",
    "        if index_num == 13:\n",
    "            break\n",
    "        plt.subplot(nrows, ncols, index_num)\n",
    "        plt.title('Boxplot de {}'.format(col))\n",
    "        plt.xlabel(col)\n",
    "        sns.boxplot(x=df[col])\n",
    "\n",
    "        plt.grid()\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # cálculo dos outliers\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 -Q1\n",
    "        upper_cap = Q3 + 1.5*IQR\n",
    "        lower_cap = Q1 - 1.5*IQR\n",
    "        print('Q1: ',Q1)\n",
    "        print('Q3: ',Q3)\n",
    "        print('IQR: ',IQR)\n",
    "        print('upper_cap: ',upper_cap)\n",
    "        print('lower_cap:',lower_cap)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap da matriz de correlação para as variaveis numericas sem o target\n",
    "\n",
    "df_num = df[var_num_plot]\n",
    "display(df_num.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "df_num_corr = df_num.corr()\n",
    "\n",
    "mask_triu = np.triu(df_num_corr,k=0)\n",
    "\n",
    "plt.title('Matriz de Correlação das Variáveis Nméricas')\n",
    "sns.heatmap(df_num_corr, annot=True, fmt='.2f', square=True, cmap = 'Blues_r', mask=mask_triu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(7,7))\n",
    "# sns.pairplot(data=df,hue='review_score')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-pricing",
   "metadata": {},
   "source": [
    "## Separação do dataframe de treinamento da variável de resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variavel resultado\n",
    "\n",
    "y = df['review_score'].copy()\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-anthropology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variaveis preditoras\n",
    "\n",
    "X = df.drop(columns='review_score').copy()\n",
    "\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-colonial",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-revolution",
   "metadata": {},
   "source": [
    "## Codificação das variáveis categóricas para numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LableEncoder para codificar as variaveis categoricas como numeros\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in list(X.columns):\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = encoder.fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-lambda",
   "metadata": {},
   "source": [
    "## Resultados dos Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-plymouth",
   "metadata": {},
   "source": [
    "### Função que treina o modelo e mostra as metricas dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cálculo e resultado do modelo\n",
    "\n",
    "def calc_and_metrics(X,y,modelo):\n",
    "    \n",
    "    # separação da base de teste (20% do total de linhas) e da base de teste (80% do total de linhas)\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state = 11)\n",
    "    \n",
    "    # treinamento do modelo\n",
    "    classificador = modelo(random_state=11)\n",
    "    classificador = classificador.fit(X_train,y_train)\n",
    "    y_pred = classificador.predict(X_test)\n",
    "\n",
    "    # confusion matrix\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "    print('tn:',tn)\n",
    "    print('fp:',fp)\n",
    "    print('fn:',fn)\n",
    "    print('tp:',tp)\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    soma_pred_true = tp+fp+fn+tn\n",
    "\n",
    "    print('soma tp,fp,fn,tp: ', soma_pred_true)\n",
    "    print('len y_test: ',len(y_test))\n",
    "\n",
    "    plot_confusion_matrix(classificador,X_test,y_test, labels=[1,0], cmap='Blues')\n",
    "    plt.show()\n",
    "\n",
    "    # metricas do resultado do modelo\n",
    "\n",
    "    precision = np.round(tp/(tp+fp),2)\n",
    "    recall = np.round(tp/(tp+fn),2)\n",
    "    accuracy = np.round((tp+tn)/soma_pred_true,2)\n",
    "    f_score = np.round((2*recall*precision)/(recall+precision),2)\n",
    "    print('precision: ',precision*100)\n",
    "    print('recall: ',recall*100)\n",
    "    print('F-score: ',f_score)\n",
    "    print('accuracy test set: ',accuracy*100)\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    # acuracia da base de teste e da base de treino\n",
    "\n",
    "    train_accuracy = np.round(classificador.score(X_train, y_train), 2)\n",
    "    test_accuracy = np.round(classificador.score(X_test, y_test), 2)\n",
    "\n",
    "    print(\"Training Set Mean Accuracy = \" + str(train_accuracy))\n",
    "    print(\"Test Set Mean Accuracy = \" + str(test_accuracy))\n",
    "\n",
    "    # importancia das variaveis no modelo\n",
    "\n",
    "    df_ft_importance = pd.DataFrame({'feature_names':X.columns,'importance':classificador.feature_importances_})\n",
    "    display(df_ft_importance.sort_values(by='importance',ascending=False))\n",
    "    \n",
    "    # ROC and AUC\n",
    "    \n",
    "    plot_roc_curve(classificador,X_test,y_test)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-morrison",
   "metadata": {},
   "source": [
    "### Funão específica da árvore de decisão para a poda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arvore_decisao_poda(X,y,max_depth):\n",
    "    \n",
    "    # separação da base de teste (20% do total de linhas) e da base de teste (80% do total de linhas)\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state = 11)\n",
    "    \n",
    "    # treinamento arvore de decisao\n",
    "    classificador = DecisionTreeClassifier(max_depth=max_depth,random_state=11)\n",
    "    classificador = classificador.fit(X_train,y_train)\n",
    "    y_pred = classificador.predict(X_test)\n",
    "\n",
    "    # confusion matrix\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "    print('tn:',tn)\n",
    "    print('fp:',fp)\n",
    "    print('fn:',fn)\n",
    "    print('tp:',tp)\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    soma_pred_true = tp+fp+fn+tn\n",
    "\n",
    "    print('soma tp,fp,fn,tp: ', soma_pred_true)\n",
    "    print('len y_test: ',len(y_test))\n",
    "\n",
    "    plot_confusion_matrix(classificador,X_test,y_test, labels=[1,0], cmap='Blues')\n",
    "    plt.show()\n",
    "\n",
    "    # metricas do resultado do modelo\n",
    "\n",
    "    precision = np.round(tp/(tp+fp),2)\n",
    "    recall = np.round(tp/(tp+fn),2)\n",
    "    accuracy = np.round((tp+tn)/soma_pred_true,2)\n",
    "    f_score = np.round((2*recall*precision)/(recall+precision),2)\n",
    "    print('precision: ',precision*100)\n",
    "    print('recall: ',recall*100)\n",
    "    print('F-score: ',f_score)\n",
    "    print('accuracy test set: ',accuracy*100)\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    # acuracia da base de teste e da base de treino\n",
    "\n",
    "    train_accuracy = np.round(classificador.score(X_train, y_train), 2)\n",
    "    test_accuracy = np.round(classificador.score(X_test, y_test), 2)\n",
    "\n",
    "    print(\"Training Set Mean Accuracy = \" + str(train_accuracy))\n",
    "    print(\"Test Set Mean Accuracy = \" + str(test_accuracy))\n",
    "\n",
    "    # importancia das variaveis no modelo\n",
    "\n",
    "    df_ft_importance = pd.DataFrame({'feature_names':X.columns,'importance':classificador.feature_importances_})\n",
    "    display(df_ft_importance.sort_values(by='importance',ascending=False))\n",
    "    \n",
    "    plot_roc_curve(classificador,X_test,y_test)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-pendant",
   "metadata": {},
   "source": [
    "### Decicion Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_and_metrics(X,y,DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-facility",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_and_metrics(X,y,RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-airport",
   "metadata": {},
   "source": [
    "## Avaliação do Desbalanceamento da variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = y.value_counts().plot(kind='bar', figsize=(10, 6), fontsize=13, color='#087E8B')\n",
    "ax.set_title('0 = rejeitado, 1 = aprovado)', size=20, pad=30)\n",
    "ax.set_ylabel('Number of transactions', fontsize=14)\n",
    "\n",
    "print('percentual da diferença: ',str(round(((np.sum(y==1)-np.sum(y==0))/len(y))*100)),'%')\n",
    "\n",
    "for i in ax.patches:\n",
    "    ax.text(i.get_x(), i.get_height() + 700, str(round(i.get_height(), 2)) + '  ' + '(' +str(round((i.get_height()/len(y))*100, 2)) + ' %' + ')', fontsize=15)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-device",
   "metadata": {},
   "source": [
    "### Aplicando o SMOTE nas variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicando o SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=10)\n",
    "\n",
    "X_sm, y_sm = sm.fit_resample(X,y)\n",
    "\n",
    "ax = y_sm.value_counts().plot(kind='bar', figsize=(10, 6), fontsize=13, color='#087E8B')\n",
    "ax.set_title('0 = rejeitado, 1 = aprovado)', size=20, pad=30)\n",
    "ax.set_ylabel('Number of transactions', fontsize=14)\n",
    "\n",
    "for i in ax.patches:\n",
    "    ax.text(i.get_x() + 0.19, i.get_height() + 700, str(round(i.get_height(), 2)), fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-better",
   "metadata": {},
   "source": [
    "## Treinamento e resultados numericos para o dataframe transformado com o SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classificador,X_test,y_test = calc_and_metrics(X_sm,y_sm,DecisionTreeClassifier)\n",
    "calc_and_metrics(X_sm,y_sm,DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alteração nos hyperparametros para ver se o modelo tem resultado melhor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "calc_and_metrics(X_sm,y_sm,RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-clear",
   "metadata": {},
   "source": [
    "## Podando a arvore de decisao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separação da base de teste (20% do total de linhas) e da base de teste (80% do total de linhas)\n",
    "X_train_sm,X_test_sm,y_train_sm,y_test_sm = train_test_split(X_sm,y_sm,test_size=0.2, random_state = 11)\n",
    "\n",
    "# alterando para 10 a quantidade de ramos desde a raiz\n",
    "clf_dt = DecisionTreeClassifier(random_state=11)\n",
    "clf_dt = clf_dt.fit(X_train_sm,y_train_sm)\n",
    "\n",
    "dt_depth = clf_dt.get_depth()\n",
    "\n",
    "print(clf_dt.get_params())\n",
    "print('\\n')\n",
    "print('qtd ramos desde raiz: ', dt_depth)\n",
    "print('\\n')\n",
    "print('qtd folhas arvore: ',clf_dt.get_n_leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultados as alterações do hyperparametro de 1 até dt_depth\n",
    "\n",
    "lista_resultado = []\n",
    "\n",
    "for depth in range(1,dt_depth + 1):\n",
    "                      \n",
    "        classifier = DecisionTreeClassifier(max_depth=depth,random_state=11)\n",
    "        classifier = classifier.fit(X_train_sm,y_train_sm)\n",
    "        y_pred_sm = classifier.predict(X_test_sm)\n",
    "\n",
    "        # confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test_sm,y_pred_sm).ravel()\n",
    "        \n",
    "        precision = np.round(tp/(tp+fp),2)\n",
    "        recall = np.round(tp/(tp+fn),2)\n",
    "        f_score = np.round((2*recall*precision)/(recall+precision),2)\n",
    "        \n",
    "        train_accuracy = np.round(classifier.score(X_train_sm, y_train_sm), 2)\n",
    "        test_accuracy = np.round(classifier.score(X_test_sm, y_test_sm), 2)\n",
    "        \n",
    "        lista_resultado.append([depth,precision,recall,f_score,train_accuracy,test_accuracy])\n",
    "        \n",
    "# print(lista_resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados_pruning = pd.DataFrame(lista_resultado,columns=['max_depth','precision','recall','f_score','train_accuracy','test_accuracy'])\n",
    "display(df_resultados_pruning.sort_values(by=['test_accuracy','f_score','precision','recall'],ascending=[False,False,False,False]).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-vitamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_decisao_poda(X_sm,y_sm,39)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
